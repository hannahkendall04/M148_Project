{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotADirectoryError",
     "evalue": "[WinError 267] The directory name is invalid: 'C:\\\\Users\\\\Ruby Riley\\\\OneDrive\\\\Desktop\\\\CS148\\\\M148_Project\\\\hannah\\\\clean_data.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m#Load data\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC:\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mUsers\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mRuby Riley\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mOneDrive\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mDesktop\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mCS148\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mM148_Project\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mhannah\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mclean_data.xlsx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m, index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     17\u001b[0m data\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[1;31mNotADirectoryError\u001b[0m: [WinError 267] The directory name is invalid: 'C:\\\\Users\\\\Ruby Riley\\\\OneDrive\\\\Desktop\\\\CS148\\\\M148_Project\\\\hannah\\\\clean_data.xlsx'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import sample\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples, rand_score, adjusted_rand_score\n",
    "from itertools import product\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 150)\n",
    "\n",
    "#Load data\n",
    "data = pd.read_excel(\"\", index_col=-1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove nominal categorical variables\n",
    "data = data.drop(data.columns[[0]], axis=1)\n",
    "data = data.drop(columns=['track_id', 'artists', 'album_name','track_name'])\n",
    "\n",
    "#convert explicit to binary variables\n",
    "data['explicit'] = data['explicit'].astype(int)\n",
    "\n",
    "# Subset the data to only the following genres: [acoustic, afrobeat, alt-rock, alternative, ambient, anime, black-metal, bluegrass, blues]\n",
    "genre = [\"acoustic\", \"children\", \"alternative\", \"classical\", \"death-metal\", \"club\", \"blues\"]\n",
    "sampled_df = data.loc[genre]\n",
    "sampled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hierarchical clustering \n",
    "\n",
    "hclust = AgglomerativeClustering(n_clusters=7, metric='euclidean', linkage='ward')\n",
    "data_hclust_labels = hclust.fit(data).labels_\n",
    "\n",
    "#visualize the clusters\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,10))\n",
    "# plot using the first 2 variables\n",
    "plt.scatter(data.iloc[:,0], data.iloc[:,1], c = data_hclust_labels, cmap='rainbow')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kmeans\n",
    "kmeans = KMeans(n_clusters=7)\n",
    "y_kmeans = kmeans.fit_predict(data)\n",
    "print(kmeans.cluster_centers_)\n",
    "\n",
    "# Add additional code to examine the clusters\n",
    "#Visualizing the clusters and cluster centers\n",
    "centroids = kmeans.cluster_centers_\n",
    "print(centroids)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "# Using same two variables as in hierarchical clustering\n",
    "plt.scatter(data.iloc[:,0], data.iloc[:,1], c = y_kmeans, cmap='rainbow')\n",
    "plt.scatter(centroids[:, 0], centroids[:, 1], c='black', s=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code is provided to you to examine the clusters\n",
    "\n",
    "def sample__cluster(activity, cluster, seed):\n",
    "    samples_by_cluster = (pd.DataFrame({\"activity\": activity,\n",
    "                                        \"cluster\": cluster})\n",
    "          .groupby(cluster)\n",
    "          .sample(15, random_state = seed))\n",
    "    # make sure the index is repeated in each group\n",
    "    samples_by_cluster.index = 6 * list(np.arange(15))\n",
    "    # pivot to wider format\n",
    "    samples_by_cluster = samples_by_cluster.pivot(columns=\"cluster\").droplevel(axis=1, level=0)\n",
    "    # add word cluster to column names\n",
    "    samples_by_cluster.columns = [\"cluster_\" + str(i) for i in samples_by_cluster.columns]\n",
    "\n",
    "    return samples_by_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine clusters for kmeans clustering\n",
    "sample__cluster(data['genre'], y_kmeans, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine clusters for hierarchical clustering\n",
    "sample__cluster(data['genre'], data, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_sample = data.sample(n= 1000, random_state=1111)\n",
    "#      i) the data colored by activity label\n",
    "plt.scatter(r_sample.iloc[:,0], r_sample.iloc[:,1], c = r_sample['genre'], cmap='rainbow')\n",
    "plt.show()\n",
    "#      ii) the data colored by the hiearchical cluster label\n",
    "hclust_sample = pd.Series(data_hclust_labels).sample(1000, random_state=1111)\n",
    "plt.scatter(r_sample.iloc[:,0], r_sample.iloc[:,1], c = hclust_sample, cmap = 'rainbow')\n",
    "plt.show()\n",
    "#     iii) the data colored by the k-means cluster label\n",
    "kmeans_sample = pd.Series(y_kmeans).sample(1000, random_state=1111)\n",
    "plt.scatter(r_sample.iloc[:,0], r_sample.iloc[:,1], c = kmeans_sample, cmap = 'rainbow')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WSS\n",
    "def tot_within_sum_of_square(data, clusters):\n",
    "    wcss = 0\n",
    "\n",
    "    # Get unique cluster labels\n",
    "    unique_clusters = np.unique(clusters)\n",
    "\n",
    "    # Loop through each unique cluster\n",
    "    for cluster in unique_clusters:\n",
    "        # Get points that belong to the current cluster\n",
    "        cluster_points = data[np.array(clusters) == cluster]\n",
    "\n",
    "        # Calculate the centroid of the cluster (mean of points in the cluster)\n",
    "        centroid = np.mean(cluster_points, axis=0)\n",
    "\n",
    "        # Calculate the sum of squared distances from each point to the centroid\n",
    "        distance_squared = np.sum(np.linalg.norm(cluster_points - centroid, axis=1) ** 2)\n",
    "\n",
    "        # Add to the total WCSS\n",
    "        wcss += distance_squared\n",
    "\n",
    "    return wcss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#k-means inertia\n",
    "print(\"K-Means Inertia:\", round(kmeans.inertia_, 1))\n",
    "# cluster sum of squares K-means\n",
    "print(\"Total Within Cluster Sum of Squares K-Means:\", tot_within_sum_of_square(data, y_kmeans))\n",
    "# cluster sum of squres hclust\n",
    "print(\"Total Within Cluster Sum of Squares HClust:\", tot_within_sum_of_square(data, data_hclust_labels))\n",
    "#silhouette score for k-means\n",
    "print(\"Silhouette Score for K-Means:\", silhouette_score(data, y_kmeans))\n",
    "#silhouette score for hclust\n",
    "print(\"Silhouette Score for Hierarchical Clustering:\", silhouette_score(data, data_hclust_labels))\n",
    "#rand score\n",
    "print(\"Rand Score:\", rand_score(y_kmeans, data_hclust_labels))\n",
    "#adj rand score\n",
    "print(\"Adjusted Rand Score:\", adjusted_rand_score(y_kmeans, data_hclust_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=10, svd_solver='full')\n",
    "pca.fit(np.asarray(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proportion of variance explained by each PC\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "\n",
    "# Cumulative variance explained by each PC\n",
    "cumulative_variance = np.cumsum(explained_variance)\n",
    "\n",
    "# Create a DataFrame to display these values\n",
    "variance_df = pd.DataFrame({\n",
    "    'PC': [f'PC{i+1}' for i in range(len(explained_variance))],\n",
    "    'Proportion of Variance Explained': explained_variance,\n",
    "    'Cumulative Variance Explained': cumulative_variance\n",
    "})\n",
    "\n",
    "# Show the table of these values for the first 10 PCs\n",
    "print(variance_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scree plot of the PCs against the percentage of variability\n",
    "# explained for the first 10 PCs\n",
    "eigenvals = pca.explained_variance_\n",
    "eigenvecs = pca.components_\n",
    "\n",
    "ids = eigenvals.argsort()[::-1]\n",
    "sorted_eigenvals = eigenvals[ids]\n",
    "sorted_eigenvecs = eigenvecs[:,ids]\n",
    "plt.plot(range(1,11),sorted_eigenvals[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiply the original data and the PCA loadings\n",
    "pca_transformed = np.matmul(data, np.transpose(pca.components_))\n",
    "# make the data easier to work with by\n",
    "# changing the column names to PC1, PC2, etc\n",
    "pca_transformed.columns = [\"PC1\", \"PC2\", \"PC3\", \"PC4\", \"PC5\", \"PC6\", \"PC7\", \"PC8\", \"PC9\", \"PC10\"]\n",
    "# look at the object\n",
    "pca_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO DO: Write code here using the entire PCA-transformed\n",
    "#    To create a single plot containing  create 3 scatter plots\n",
    "#    using PC1 and PC2 for the\n",
    "#      i) the data colored by activity label\n",
    "plt.scatter(pca_transformed.iloc[:,0], pca_transformed.iloc[:,1], c= data[\"genre\"], cmap='rainbow')\n",
    "plt.show()\n",
    "#      ii) the data colored by the original hierarchical cluster label\n",
    "plt.scatter(pca_transformed.iloc[:,0], pca_transformed.iloc[:,1], c= data_hclust_labels, cmap='rainbow')\n",
    "plt.show()\n",
    "#     iii) the data colored by the original k-means cluster label\n",
    "plt.scatter(pca_transformed.iloc[:,0], pca_transformed.iloc[:,1], c= y_kmeans, cmap='rainbow')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clustering and PCA\n",
    "#TO DO: Add code here using the number of PCs you chose to use\n",
    "# 1. Perform hierarchical clustering on the PCA-transformed data\n",
    "hclust_pca = AgglomerativeClustering(n_clusters=7, metric='euclidean', linkage='ward')\n",
    "data_hclust_labels_pca = hclust_pca.fit(pca_transformed).labels_\n",
    "# 2. Perform k-means clustering on the PCA-transformed data\n",
    "kmeans_pca = KMeans(n_clusters=7)\n",
    "y_kmeans_pca = kmeans_pca.fit_predict(pca_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO DO: Write code here using the entire PCA-transformed\n",
    "#    To create a single plot containing  create 3 scatter plots\n",
    "#    using PC1 and PC2 for the\n",
    "#      i) the data colored by activity label\n",
    "plt.scatter(pca_transformed.iloc[:,0], pca_transformed.iloc[:,1], c= data[\"genre\"], cmap='rainbow')\n",
    "plt.show()\n",
    "#      ii) the data colored by the pca-transformed hierarchical cluster label\n",
    "plt.scatter(pca_transformed.iloc[:,0], pca_transformed.iloc[:,1], c= data_hclust_labels_pca, cmap='rainbow')\n",
    "plt.show()\n",
    "#     iii) the data colored by the pca-transformed  k-means cluster label\n",
    "plt.scatter(pca_transformed.iloc[:,0], pca_transformed.iloc[:,1], c= y_kmeans_pca, cmap='rainbow')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add code here to calculate these metrics for the PCA-Transformed clustering\n",
    "print(\"K-Means Inertia:\", round(kmeans_pca.inertia_, 1))\n",
    "print(\"Total With Cluster Sum of Squares for K-Means:\", tot_within_sum_of_square(pca_transformed, y_kmeans_pca))\n",
    "print(\"Total With Cluster Sum of Squares for Hierarchical Clustering:\", tot_within_sum_of_square(pca_transformed, data_hclust_labels_pca))\n",
    "print(\"Silhouette Score for K-Means:\", silhouette_score(pca_transformed, y_kmeans_pca))\n",
    "print(\"Silhouette Score for Hierarchical Clustering:\", silhouette_score(pca_transformed, data_hclust_labels_pca))\n",
    "print(\"Rand Score:\", rand_score(y_kmeans_pca, data_hclust_labels_pca))\n",
    "print(\"Adjusted Rand Score for the K-Means and Hiearchical Clustering:\", adjusted_rand_score(y_kmeans_pca, data_hclust_labels_pca))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
